CREATE STREAM NEWS (title VARCHAR, summary VARCHAR, category VARCHAR, source VARCHAR, date VARCHAR)
  WITH (KAFKA_TOPIC='news', PARTITIONS=1, VALUE_FORMAT='AVRO');

GRANT  CREATE, ALTER, DROP, SELECT, INSERT, UPDATE, DELETE ON demo.* TO connect_user;

INSERT INTO NEWS (title, summary ,category , source , date ) VALUES ('test title','jaldi se khatm karo ye program','sports','myownsource','10-09-2021');

curl -X PUT http://kafka-connect:8083/connectors/sink-jdbc-mysql-01/config \
-H "Content-Type: application/json" -d '{
    "connector.class"                    : "io.confluent.connect.jdbc.JdbcSinkConnector",
    "connection.url"                     : "jdbc:mysql://mysql:3306/demo",
    "topics"                             : "news",
    "key.converter"                      : "org.apache.kafka.connect.storage.StringConverter",
    "value.converter"                    : "io.confluent.connect.avro.AvroConverter",
    "value.converter.schema.registry.url": "http://schema-registry:8081",
    "connection.user"                    : "connect_user",
    "connection.password"                : "asgard",
    "auto.create"                        : true,
    "auto.evolve"                        : true,
    "insert.mode"                        : "insert"
}'

run create_db_demo sql file from docker-compose

curl -s http://localhost:8083/connectors/sink-jdbc-mysql-01/tasks/0/status